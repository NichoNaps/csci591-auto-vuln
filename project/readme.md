



Optionally setup a virt environment
```sh
python -m venv env # create python virt env
source env/bin/activate # activate python virt env
```


```sh
pip install huggingface-hub
```

There are a bazillion ways to install llama-cpp-python depending on what kind of gpu/cpu support you want: https://llama-cpp-python.readthedocs.io/en/latest/. The following only installs CPU support.

```sh
install llama-cpp-python
```

Add these flags if you need to re-install llama-cpp-python with diff cmake flags
--no-cache-dir --force-reinstall




